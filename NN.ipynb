{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75627, 25209)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "train_set, test_set = ms.train_test_split(df, test_size=0.25)\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(train_set, dtype = 'int')\n",
    "testing_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = df.userId.unique().shape[0]\n",
    "num_items = df.movieId.unique().shape[0]\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_movieId = df.movieId.unique().tolist()\n",
    "movie_movieId.sort()\n",
    "d = dict()\n",
    "for i in range(0, len(movie_movieId)):\n",
    "    d[movie_movieId[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_matrix(data):\n",
    "    ratings = np.zeros((num_users, num_items))\n",
    "    for row in data.itertuples():\n",
    "        ratings[row[1]-1, d[row[2]]] = row[3]\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = user_item_matrix(df)\n",
    "train = user_item_matrix(train_set)\n",
    "test = user_item_matrix(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 610, 9724])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = torch.FloatTensor(train)\n",
    "input = Variable(train).unsqueeze(0)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.FloatTensor(train)\n",
    "test = torch.FloatTensor(test)\n",
    "input = Variable(train).unsqueeze(0)\n",
    "target = input\n",
    "torch_dataset = Data.TensorDataset(input, target)\n",
    "loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_items, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, num_items)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.activation_t = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation_t(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "loss_func = nn.MSELoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=LR, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | train loss:  0.17093757\n",
      "Epoch:  1 | Step:  0 | train loss:  0.16165143\n",
      "Epoch:  2 | Step:  0 | train loss:  0.15256897\n",
      "Epoch:  3 | Step:  0 | train loss:  0.14355434\n",
      "Epoch:  4 | Step:  0 | train loss:  0.13465391\n",
      "Epoch:  5 | Step:  0 | train loss:  0.12593271\n",
      "Epoch:  6 | Step:  0 | train loss:  0.117445774\n",
      "Epoch:  7 | Step:  0 | train loss:  0.109210126\n",
      "Epoch:  8 | Step:  0 | train loss:  0.10117807\n",
      "Epoch:  9 | Step:  0 | train loss:  0.093316734\n",
      "Epoch:  10 | Step:  0 | train loss:  0.085613444\n",
      "Epoch:  11 | Step:  0 | train loss:  0.078049645\n",
      "Epoch:  12 | Step:  0 | train loss:  0.07058457\n",
      "Epoch:  13 | Step:  0 | train loss:  0.06325416\n",
      "Epoch:  14 | Step:  0 | train loss:  0.05600365\n",
      "Epoch:  15 | Step:  0 | train loss:  0.048936885\n",
      "Epoch:  16 | Step:  0 | train loss:  0.042190157\n",
      "Epoch:  17 | Step:  0 | train loss:  0.035790578\n",
      "Epoch:  18 | Step:  0 | train loss:  0.02989061\n",
      "Epoch:  19 | Step:  0 | train loss:  0.024678001\n",
      "Epoch:  20 | Step:  0 | train loss:  0.020260815\n",
      "Epoch:  21 | Step:  0 | train loss:  0.016763015\n",
      "Epoch:  22 | Step:  0 | train loss:  0.014345268\n",
      "Epoch:  23 | Step:  0 | train loss:  0.01327685\n",
      "Epoch:  24 | Step:  0 | train loss:  0.013446601\n",
      "Epoch:  25 | Step:  0 | train loss:  0.014129354\n",
      "Epoch:  26 | Step:  0 | train loss:  0.014851491\n",
      "Epoch:  27 | Step:  0 | train loss:  0.015453923\n",
      "Epoch:  28 | Step:  0 | train loss:  0.015801936\n",
      "Epoch:  29 | Step:  0 | train loss:  0.01573894\n",
      "Epoch:  30 | Step:  0 | train loss:  0.015390302\n",
      "Epoch:  31 | Step:  0 | train loss:  0.014740635\n",
      "Epoch:  32 | Step:  0 | train loss:  0.01395941\n",
      "Epoch:  33 | Step:  0 | train loss:  0.01309106\n",
      "Epoch:  34 | Step:  0 | train loss:  0.012235443\n",
      "Epoch:  35 | Step:  0 | train loss:  0.011456818\n",
      "Epoch:  36 | Step:  0 | train loss:  0.0107972855\n",
      "Epoch:  37 | Step:  0 | train loss:  0.010303453\n",
      "Epoch:  38 | Step:  0 | train loss:  0.009977053\n",
      "Epoch:  39 | Step:  0 | train loss:  0.009802776\n",
      "Epoch:  40 | Step:  0 | train loss:  0.009758735\n",
      "Epoch:  41 | Step:  0 | train loss:  0.009809924\n",
      "Epoch:  42 | Step:  0 | train loss:  0.0099217445\n",
      "Epoch:  43 | Step:  0 | train loss:  0.010057811\n",
      "Epoch:  44 | Step:  0 | train loss:  0.010189963\n",
      "Epoch:  45 | Step:  0 | train loss:  0.010299386\n",
      "Epoch:  46 | Step:  0 | train loss:  0.010371591\n",
      "Epoch:  47 | Step:  0 | train loss:  0.010400375\n",
      "Epoch:  48 | Step:  0 | train loss:  0.010384634\n",
      "Epoch:  49 | Step:  0 | train loss:  0.010329359\n",
      "Epoch:  50 | Step:  0 | train loss:  0.010242089\n",
      "Epoch:  51 | Step:  0 | train loss:  0.010132669\n",
      "Epoch:  52 | Step:  0 | train loss:  0.01001162\n",
      "Epoch:  53 | Step:  0 | train loss:  0.009889772\n",
      "Epoch:  54 | Step:  0 | train loss:  0.009776531\n",
      "Epoch:  55 | Step:  0 | train loss:  0.009679189\n",
      "Epoch:  56 | Step:  0 | train loss:  0.009602748\n",
      "Epoch:  57 | Step:  0 | train loss:  0.00954939\n",
      "Epoch:  58 | Step:  0 | train loss:  0.009517634\n",
      "Epoch:  59 | Step:  0 | train loss:  0.009502924\n",
      "Epoch:  60 | Step:  0 | train loss:  0.009499372\n",
      "Epoch:  61 | Step:  0 | train loss:  0.0094979135\n",
      "Epoch:  62 | Step:  0 | train loss:  0.009491501\n",
      "Epoch:  63 | Step:  0 | train loss:  0.009479385\n",
      "Epoch:  64 | Step:  0 | train loss:  0.009464283\n",
      "Epoch:  65 | Step:  0 | train loss:  0.009452167\n",
      "Epoch:  66 | Step:  0 | train loss:  0.00944844\n",
      "Epoch:  67 | Step:  0 | train loss:  0.009450681\n",
      "Epoch:  68 | Step:  0 | train loss:  0.00944673\n",
      "Epoch:  69 | Step:  0 | train loss:  0.0094344895\n",
      "Epoch:  70 | Step:  0 | train loss:  0.009421816\n",
      "Epoch:  71 | Step:  0 | train loss:  0.00941435\n",
      "Epoch:  72 | Step:  0 | train loss:  0.00941044\n",
      "Epoch:  73 | Step:  0 | train loss:  0.009404706\n",
      "Epoch:  74 | Step:  0 | train loss:  0.009394347\n",
      "Epoch:  75 | Step:  0 | train loss:  0.00938126\n",
      "Epoch:  76 | Step:  0 | train loss:  0.009367909\n",
      "Epoch:  77 | Step:  0 | train loss:  0.009356197\n",
      "Epoch:  78 | Step:  0 | train loss:  0.009346352\n",
      "Epoch:  79 | Step:  0 | train loss:  0.00933339\n",
      "Epoch:  80 | Step:  0 | train loss:  0.009312834\n",
      "Epoch:  81 | Step:  0 | train loss:  0.009288658\n",
      "Epoch:  82 | Step:  0 | train loss:  0.009274682\n",
      "Epoch:  83 | Step:  0 | train loss:  0.009264016\n",
      "Epoch:  84 | Step:  0 | train loss:  0.009249138\n",
      "Epoch:  85 | Step:  0 | train loss:  0.009228588\n",
      "Epoch:  86 | Step:  0 | train loss:  0.009211248\n",
      "Epoch:  87 | Step:  0 | train loss:  0.009195931\n",
      "Epoch:  88 | Step:  0 | train loss:  0.009172786\n",
      "Epoch:  89 | Step:  0 | train loss:  0.00915332\n",
      "Epoch:  90 | Step:  0 | train loss:  0.00912504\n",
      "Epoch:  91 | Step:  0 | train loss:  0.00910336\n",
      "Epoch:  92 | Step:  0 | train loss:  0.009077136\n",
      "Epoch:  93 | Step:  0 | train loss:  0.009053345\n",
      "Epoch:  94 | Step:  0 | train loss:  0.009024772\n",
      "Epoch:  95 | Step:  0 | train loss:  0.00899791\n",
      "Epoch:  96 | Step:  0 | train loss:  0.008976626\n",
      "Epoch:  97 | Step:  0 | train loss:  0.008952535\n",
      "Epoch:  98 | Step:  0 | train loss:  0.008927972\n",
      "Epoch:  99 | Step:  0 | train loss:  0.008901182\n",
      "Epoch:  100 | Step:  0 | train loss:  0.008862303\n",
      "Epoch:  101 | Step:  0 | train loss:  0.008851777\n",
      "Epoch:  102 | Step:  0 | train loss:  0.008825645\n",
      "Epoch:  103 | Step:  0 | train loss:  0.008809465\n",
      "Epoch:  104 | Step:  0 | train loss:  0.008791437\n",
      "Epoch:  105 | Step:  0 | train loss:  0.00877346\n",
      "Epoch:  106 | Step:  0 | train loss:  0.008759083\n",
      "Epoch:  107 | Step:  0 | train loss:  0.00874737\n",
      "Epoch:  108 | Step:  0 | train loss:  0.008722893\n",
      "Epoch:  109 | Step:  0 | train loss:  0.008708589\n",
      "Epoch:  110 | Step:  0 | train loss:  0.0086925505\n",
      "Epoch:  111 | Step:  0 | train loss:  0.008665735\n",
      "Epoch:  112 | Step:  0 | train loss:  0.008660355\n",
      "Epoch:  113 | Step:  0 | train loss:  0.008647882\n",
      "Epoch:  114 | Step:  0 | train loss:  0.008633582\n",
      "Epoch:  115 | Step:  0 | train loss:  0.0086114835\n",
      "Epoch:  116 | Step:  0 | train loss:  0.008586236\n",
      "Epoch:  117 | Step:  0 | train loss:  0.008572474\n",
      "Epoch:  118 | Step:  0 | train loss:  0.008560805\n",
      "Epoch:  119 | Step:  0 | train loss:  0.008550439\n",
      "Epoch:  120 | Step:  0 | train loss:  0.008544925\n",
      "Epoch:  121 | Step:  0 | train loss:  0.008536747\n",
      "Epoch:  122 | Step:  0 | train loss:  0.008530943\n",
      "Epoch:  123 | Step:  0 | train loss:  0.008525407\n",
      "Epoch:  124 | Step:  0 | train loss:  0.008521601\n",
      "Epoch:  125 | Step:  0 | train loss:  0.008516026\n",
      "Epoch:  126 | Step:  0 | train loss:  0.008508351\n",
      "Epoch:  127 | Step:  0 | train loss:  0.008502105\n",
      "Epoch:  128 | Step:  0 | train loss:  0.008497841\n",
      "Epoch:  129 | Step:  0 | train loss:  0.008494144\n",
      "Epoch:  130 | Step:  0 | train loss:  0.00849\n",
      "Epoch:  131 | Step:  0 | train loss:  0.008486298\n",
      "Epoch:  132 | Step:  0 | train loss:  0.008482507\n",
      "Epoch:  133 | Step:  0 | train loss:  0.008476872\n",
      "Epoch:  134 | Step:  0 | train loss:  0.008471409\n",
      "Epoch:  135 | Step:  0 | train loss:  0.008466817\n",
      "Epoch:  136 | Step:  0 | train loss:  0.008463896\n",
      "Epoch:  137 | Step:  0 | train loss:  0.008459166\n",
      "Epoch:  138 | Step:  0 | train loss:  0.008455499\n",
      "Epoch:  139 | Step:  0 | train loss:  0.008441111\n",
      "Epoch:  140 | Step:  0 | train loss:  0.008428424\n",
      "Epoch:  141 | Step:  0 | train loss:  0.008422583\n",
      "Epoch:  142 | Step:  0 | train loss:  0.008414596\n",
      "Epoch:  143 | Step:  0 | train loss:  0.008418136\n",
      "Epoch:  144 | Step:  0 | train loss:  0.008401856\n",
      "Epoch:  145 | Step:  0 | train loss:  0.008399763\n",
      "Epoch:  146 | Step:  0 | train loss:  0.008385322\n",
      "Epoch:  147 | Step:  0 | train loss:  0.008376199\n",
      "Epoch:  148 | Step:  0 | train loss:  0.008360901\n",
      "Epoch:  149 | Step:  0 | train loss:  0.008356071\n",
      "Epoch:  150 | Step:  0 | train loss:  0.008348061\n",
      "Epoch:  151 | Step:  0 | train loss:  0.008327227\n",
      "Epoch:  152 | Step:  0 | train loss:  0.008316306\n",
      "Epoch:  153 | Step:  0 | train loss:  0.0083120335\n",
      "Epoch:  154 | Step:  0 | train loss:  0.008305536\n",
      "Epoch:  155 | Step:  0 | train loss:  0.008300828\n",
      "Epoch:  156 | Step:  0 | train loss:  0.008291781\n",
      "Epoch:  157 | Step:  0 | train loss:  0.008288786\n",
      "Epoch:  158 | Step:  0 | train loss:  0.008274304\n",
      "Epoch:  159 | Step:  0 | train loss:  0.008267304\n",
      "Epoch:  160 | Step:  0 | train loss:  0.008252906\n",
      "Epoch:  161 | Step:  0 | train loss:  0.008239463\n",
      "Epoch:  162 | Step:  0 | train loss:  0.008230456\n",
      "Epoch:  163 | Step:  0 | train loss:  0.008229959\n",
      "Epoch:  164 | Step:  0 | train loss:  0.008223356\n",
      "Epoch:  165 | Step:  0 | train loss:  0.008216192\n",
      "Epoch:  166 | Step:  0 | train loss:  0.008205187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  167 | Step:  0 | train loss:  0.008199232\n",
      "Epoch:  168 | Step:  0 | train loss:  0.008192011\n",
      "Epoch:  169 | Step:  0 | train loss:  0.008184702\n",
      "Epoch:  170 | Step:  0 | train loss:  0.008178298\n",
      "Epoch:  171 | Step:  0 | train loss:  0.008170194\n",
      "Epoch:  172 | Step:  0 | train loss:  0.008158084\n",
      "Epoch:  173 | Step:  0 | train loss:  0.00815029\n",
      "Epoch:  174 | Step:  0 | train loss:  0.0081452485\n",
      "Epoch:  175 | Step:  0 | train loss:  0.008141\n",
      "Epoch:  176 | Step:  0 | train loss:  0.008128934\n",
      "Epoch:  177 | Step:  0 | train loss:  0.008121428\n",
      "Epoch:  178 | Step:  0 | train loss:  0.00811921\n",
      "Epoch:  179 | Step:  0 | train loss:  0.008108524\n",
      "Epoch:  180 | Step:  0 | train loss:  0.008103378\n",
      "Epoch:  181 | Step:  0 | train loss:  0.008096751\n",
      "Epoch:  182 | Step:  0 | train loss:  0.008092305\n",
      "Epoch:  183 | Step:  0 | train loss:  0.008081287\n",
      "Epoch:  184 | Step:  0 | train loss:  0.008073909\n",
      "Epoch:  185 | Step:  0 | train loss:  0.008058286\n",
      "Epoch:  186 | Step:  0 | train loss:  0.008051123\n",
      "Epoch:  187 | Step:  0 | train loss:  0.008045477\n",
      "Epoch:  188 | Step:  0 | train loss:  0.008049013\n",
      "Epoch:  189 | Step:  0 | train loss:  0.008027933\n",
      "Epoch:  190 | Step:  0 | train loss:  0.008010302\n",
      "Epoch:  191 | Step:  0 | train loss:  0.008000316\n",
      "Epoch:  192 | Step:  0 | train loss:  0.007992209\n",
      "Epoch:  193 | Step:  0 | train loss:  0.007983043\n",
      "Epoch:  194 | Step:  0 | train loss:  0.007972821\n",
      "Epoch:  195 | Step:  0 | train loss:  0.00796225\n",
      "Epoch:  196 | Step:  0 | train loss:  0.007949222\n",
      "Epoch:  197 | Step:  0 | train loss:  0.007930598\n",
      "Epoch:  198 | Step:  0 | train loss:  0.007926111\n",
      "Epoch:  199 | Step:  0 | train loss:  0.007911398\n"
     ]
    }
   ],
   "source": [
    "loss_his = []\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(loader):          # for each training step\n",
    "        output = net(b_x)  \n",
    "        output[target == 0] = 0\n",
    "        # get output for every net\n",
    "        loss = loss_func(output, b_y)  # compute loss for every net\n",
    "        opt.zero_grad()                # clear gradients for next train\n",
    "        loss.backward()                # backpropagation, compute gradients\n",
    "        opt.step()                     # apply gradients\n",
    "        loss_his.append(loss.data.numpy())     # loss recoder\n",
    "        print('Epoch: ', epoch, '| Step: ', step, '| train loss: ', loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8HGd97/HPV5IlWxffZNmOL7Ecx0mwIQ3BuNAS4BAOOD00ppC0caEEmp70Ql5tD6UlnLYpBHoJPVzaQ86BtATCrSEE0rqtIQRoQy8QrNxxHMeK49iK7Vi+3y1L+vWPGdnr9Uq7sjW7kvb7fr302t1nntn9aSzrq3nmmRlFBGZmZkOpqXQBZmY2+jkszMysKIeFmZkV5bAwM7OiHBZmZlaUw8LMzIpyWJgNQtJnJP3xSPcdZg3tkkJS3Ui/t9lwyOdZ2HgkaTPwaxHx3UrXci4ktQPPARMiorey1Vg1856FVSX/pW42PA4LG3ckfQk4H/hHSYck/UHOcM4NkrYA30/7fl3SDkn7Jf1A0tKc9/mCpI+mz18vqUvS70naKWm7pPecZd9WSf8o6YCktZI+KunfS/ze5khaLWmPpE5J/zNn2XJJHen7vijpE2n7RElflrRb0r70M2ed00a2quOwsHEnIn4F2AL8fEQ0R8THcha/DngJ8Ob09beAxcBM4BHgK0O89WxgCjAXuAG4XdK0s+h7O3A47XN9+lWqvwO6gDnANcCfSboyXfZXwF9FxGRgEXBP2n59Wst8oBX4DeDoMD7TzGFhVedDEXE4Io4CRMSdEXEwIo4DHwJ+StKUQdY9AdwaESciYg1wCLh4OH0l1QJvB/4kIo5ExFPAXaUULmk+8BrgAxFxLCIeA/4W+JWcz7xQ0oyIOBQRP8ppbwUujIi+iHg4Ig6U8plmAxwWVm22DjyRVCvpLyQ9K+kAsDldNGOQdXfnHWQ+AjQPs28bUJdbR97zocwB9kTEwZy250n2XiDZg7kIeDodanpL2v4l4H7gbknbJH1M0oQSP9MMcFjY+DXYNL/c9l8GVgJvJBmmaU/blV1ZdAO9wLyctvklrrsNmC6pJaftfOAFgIjYGBGrSIbUbgPuldSU7t18OCKWAD8DvAV41zl+H1ZlHBY2Xr0IXFCkTwtwHNgNNAJ/lnVREdEHfBP4kKRGSZdQ4i/uiNgK/Cfw5+lB60tJ9ia+AiDpnZLaIqIf2Jeu1ifpv0l6WToEdoBkWKpvZL8zG+8cFjZe/TnwR+nsn/cP0ueLJMM4LwBPAT8apN9Iu4lkT2YHyRDR35GEVilWkewBbQPuIzn28UC6bAWwTtIhkoPd10XEMZID6feSBMV64EHgyyPynVjV8El5ZhUm6TZgdkQMZ1aUWVl5z8KszCRdIulSJZaTDCXdV+m6zIbis1jNyq+FZOhpDrAT+DjwDxWtyKwID0OZmVlRHoYyM7Oixs0w1IwZM6K9vb3SZZiZjSkPP/zwrohoK9Zv3IRFe3s7HR0dlS7DzGxMkfR8Kf08DGVmZkU5LMzMrCiHhZmZFeWwMDOzohwWZmZWlMPCzMyKcliYmVlRVR8W+4+e4FPffYbHt+4r3tnMrEqNm5PyzlaN4FPf3cjECbX81PyplS7HzGxUqvo9i5aJE5jeVM/zu49UuhQzs1Gr6sMCYEFrI8/vPlzpMszMRi2HBbBgeqP3LMzMhuCwAM5vbWL7/qMc7/U97M3MCnFYAO2tjfQHdO09WulSzMxGJYcFyTELgC0eijIzK8hhASxobQLwQW4zs0E4LIDWpnqa6mvZ7D0LM7OCHBaAJM5vbWLLHoeFmVkhmYaFpBWSNkjqlHRzgeWvlfSIpF5J1+QtO1/SdyStl/SUpPYsa21vbWSzh6HMzArKLCwk1QK3A1cBS4BVkpbkddsCvBv4aoG3+CLwlxHxEmA5sDOrWgHOb22ka89R+vojy48xMxuTstyzWA50RsSmiOgB7gZW5naIiM0R8QTQn9uehkpdRDyQ9jsUEZmOES2Y3kRPXz87DhzL8mPMzMakLMNiLrA153VX2laKi4B9kr4p6VFJf5nuqWSmPZ0++/wuD0WZmeXLMixUoK3UMZ464Arg/cArgQtIhqtO/wDpRkkdkjq6u7vPtk4gGYYCeN4Huc3MzpBlWHQB83NezwO2DWPdR9MhrF7g74HL8ztFxB0RsSwilrW1tZ1TsedNmUR9bY0PcpuZFZBlWKwFFktaKKkeuA5YPYx1p0kaSIA3AE9lUONJtTVi3vRJPovbzKyAzMIi3SO4CbgfWA/cExHrJN0q6WoASa+U1AVcC3xW0rp03T6SIajvSXqSZEjrb7KqdYCvPmtmVlimd8qLiDXAmry2W3KeryUZniq07gPApVnWl29BaxM/fm4PEYFU6JCLmVl18hncORa0NnK4p4/dh3sqXYqZ2ajisMgxcPVZD0WZmZ3OYZHDV581MyvMYZFj3rRJSN6zMDPL57DI0VBXy5wpk7xnYWaWx2GRZ0Fro8/iNjPL47DIs6C10SfmmZnlcVjkWdDaxO7DPRw8dqLSpZiZjRoOizwLpnv6rJlZPodFnlPTZx0WZmYDHBZ5Tl2q3DOizMwGOCzyNDfUMaO53ge5zcxyOCwKWNDa5PtamJnlcFgUsGC6p8+ameVyWBSwoLWJ7QeOcexEX6VLMTMbFRwWBbTPaCQCtvhMbjMzIOOwkLRC0gZJnZJuLrD8tZIekdQr6ZoCyydLekHSp7OsM197On32uV0+bmFmBhmGhaRa4HbgKmAJsErSkrxuW4B3A18d5G0+AjyYVY2DaZ+RhMVmh4WZGZDtnsVyoDMiNkVED3A3sDK3Q0RsjogngP78lSW9ApgFfCfDGguaMmkC05vqPSPKzCyVZVjMBbbmvO5K24qSVAN8HPj9Iv1ulNQhqaO7u/usCy1k4YwmD0OZmaWyDAsVaIsS1/0tYE1EbB2qU0TcERHLImJZW1vbsAscSntrE5t3+QC3mRlAXYbv3QXMz3k9D9hW4rqvBq6Q9FtAM1Av6VBEnHGQPCsLZzTyjUeOcaSnl8b6LDeTmdnol+VvwbXAYkkLgReA64BfLmXFiHjHwHNJ7waWlTMoIPcg9xGWzJlczo82Mxt1MhuGiohe4CbgfmA9cE9ErJN0q6SrASS9UlIXcC3wWUnrsqpnuAamz/ogt5lZtnsWRMQaYE1e2y05z9eSDE8N9R5fAL6QQXlDGtiz8EFuMzOfwT2o5oY62loafK6FmRkOiyEt9NVnzcwAh8WQ2mc08pynz5qZOSyG0j6jiV2HjnPw2IlKl2JmVlEOiyEs9P24zcwAh8WQPCPKzCzhsBjCyXMtHBZmVuUcFkOYVF/LeVMmes/CzKqew6KI9tYmnvP0WTOrcg6LItpnNHkYysyqnsOiiIUzGtl75AT7j3j6rJlVL4dFESfvx+2hKDOrYg6LIhb6ftxmZg6LYuZPb0TyuRZmVt0cFkVMnFDLnCmTfEFBM6tqmYaFpBWSNkjqlHTGne4kvVbSI5J6JV2T036ZpB9KWifpCUm/lGWdxSz0jCgzq3KZhYWkWuB24CpgCbBK0pK8bluAdwNfzWs/ArwrIpYCK4BPSZqaVa3FJFefPUxEVKoEM7OKynLPYjnQGRGbIqIHuBtYmdshIjZHxBNAf177MxGxMX2+DdgJtGVY65DaW5s4cKyXvZ4+a2ZVKsuwmAtszXndlbYNi6TlQD3wbIFlN0rqkNTR3d191oUWs/DkBQUPZfYZZmajWZZhoQJtwxrHkXQe8CXgPRHRn788Iu6IiGURsaytLbsdj1NXn/Wlys2sOmUZFl3A/JzX84Btpa4saTLwz8AfRcSPRri2YZk/rZHaGvkgt5lVrSzDYi2wWNJCSfXAdcDqUlZM+98HfDEivp5hjSWpr6th/rRJPtfCzKpWZmEREb3ATcD9wHrgnohYJ+lWSVcDSHqlpC7gWuCzktalq/8i8Frg3ZIeS78uy6rWUixqa+bZbh+zMLPqVJflm0fEGmBNXtstOc/XkgxP5a/3ZeDLWdY2XItmNvNvnbvo6w9qawodjjEzG798BneJFrU10dPbzwt7j1a6FDOzsnNYlGhRWzOAh6LMrCo5LEo0EBadOx0WZlZ9HBYlmtZUT2tTvfcszKwqOSyGwTOizKxaOSyGYdHMJp7t9rkWZlZ9HBbDsKitmT2He9hzuKfSpZiZlZXDYhgGDnJv8lCUmVUZh8UwXDjT02fNrDo5LIZhztRJNNTVePqsmVUdh8Uw1NaIhTN8kNvMqo/DYpgWzfT0WTOrPg6LYVrU1szWPUc4dqKv0qWYmZWNw2KYFrU10R/w/G7fNc/MqofDYph8QUEzq0aZhoWkFZI2SOqUdHOB5a+V9IikXknX5C27XtLG9Ov6LOscjpNh4RlRZlZFMgsLSbXA7cBVwBJglaQled22AO8Gvpq37nTgT4CfBpYDfyJpWla1Dsek+lrmTp1Ep/cszKyKZLlnsRzojIhNEdED3A2szO0QEZsj4gmgP2/dNwMPRMSeiNgLPACsyLDWYfGMKDOrNlmGxVxga87rrrRtxNaVdKOkDkkd3d3dZ13ocC1qa+LZnYfp74+yfaaZWSVlGRaFblRd6m/XktaNiDsiYllELGtraxtWcediUVszR0/0sePAsbJ9pplZJWUZFl3A/JzX84BtZVg3c54RZWbVJsuwWAsslrRQUj1wHbC6xHXvB94kaVp6YPtNaduosGhmE+AZUWZWPTILi4joBW4i+SW/HrgnItZJulXS1QCSXimpC7gW+Kykdem6e4CPkATOWuDWtG1UaGtuYPLEOl8jysyqRl0pnSQtAroi4rik1wOXAl+MiH1DrRcRa4A1eW235DxfSzLEVGjdO4E7S6mv3CSxaGazrz5rZlWj1D2LbwB9ki4EPgcsJO/ciGrj+3GbWTUpNSz602GlXwA+FRH/Czgvu7JGv0Vtzew8eJwDx05UuhQzs8yVGhYnJK0Crgf+KW2bkE1JY8OiNh/kNrPqUWpYvAd4NfCnEfGcpIXAl7Mra/S7aFYLABsdFmZWBUo6wB0RTwG/DZBOZW2JiL/IsrDRbv70Rhrqatj44sFKl2JmlrmS9iwk/aukyekF/h4HPi/pE9mWNrrV1ohFbc0886L3LMxs/Ct1GGpKRBwA3gZ8PiJeAbwxu7LGhsWzPH3WzKpDqWFRJ+k84Bc5dYC76l00q4UX9h3l0PHeSpdiZpapUsPiVpIzsZ+NiLWSLgA2ZlfW2LB4ZnKNKB+3MLPxrqSwiIivR8SlEfGb6etNEfH2bEsb/RZ7RpSZVYlSD3DPk3SfpJ2SXpT0DUkFL9NRTc73jCgzqxKlDkN9nuSKsXNIbkL0j2lbVfOMKDOrFqWGRVtEfD4ietOvLwDlu9vQKOYZUWZWDUoNi12S3impNv16J7A7y8LGCs+IMrNqUGpY/CrJtNkdwHbgGpJLgFS9Cz0jysyqQKmzobZExNUR0RYRMyPirSQn6A1J0gpJGyR1Srq5wPIGSV9Llz8kqT1tnyDpLklPSlov6YPD/L7KxteIMrNqcC53ynvfUAsl1QK3A1cBS4BVkpbkdbsB2BsRFwKfBG5L268FGiLiZcArgF8fCJLR5vzpjdR7RpSZjXPnEhYqsnw50Jmek9ED3A2szOuzErgrfX4vcKUkAQE0SaoDJgE9wIFzqDUzAzOivGdhZuPZuYRFFFk+F9ia87orbSvYJ7250n6glSQ4DpMcH9kC/J/RdA/ufBfNamajp8+a2Tg2ZFhIOijpQIGvgyTnXAy5eoG2/IAZrM9yoC/9jIXA76WXGMmv70ZJHZI6uru7i5STHc+IMrPxbsiwiIiWiJhc4KslIordC6MLmJ/zeh6wbbA+6ZDTFGAP8MvAtyPiRETsBP4DWFagvjsiYllELGtrq9xpHwMzony+hZmNV+cyDFXMWmCxpIWS6oHrSM4Cz7Wa5FatkEzH/X5EBMnQ0xuUaAJeBTydYa3nZGBG1DM+yG1m41RmYZEeg7iJ5Gq164F7ImKdpFslXZ12+xzQKqmTZHbVwPTa24Fm4CckofP5iHgiq1rPlWdEmdl4V9JtVc9WRKwB1uS13ZLz/BjJNNn89Q4Vah+tPCPKzMa7LIehqopnRJnZeOawGCGLZzZ7RpSZjVsOixEycCMkz4gys/HIYTFCBm6x6hlRZjYeOSxGyILWJs+IMrNxy2ExQnzXPDMbzxwWIyiZEeU9CzMbfxwWI+ji2S1s23+M/UdPVLoUM7MR5bAYQZfM9mU/zGx8cliMoIFrRD29w2FhZuOLw2IEzZ06iZaGOp5xWJjZOOOwGEGSuGh2CxscFmY2zjgsRtjFs1t4escBkiutm5mNDw6LEXbxrBYOHOtlx4FjlS7FzGzEOCxG2MXpjCgPRZnZeOKwGGGXOCzMbBzKNCwkrZC0QVKnpJsLLG+Q9LV0+UOS2nOWXSrph5LWSXpS0sQsax0pUxvrmTW5wWFhZuNKZmEhqZbk9qhXAUuAVZKW5HW7AdgbERcCnwRuS9etA74M/EZELAVeD4yZ06IvmtXicy3MbFzJcs9iOdAZEZsioge4G1iZ12clcFf6/F7gSkkC3gQ8ERGPA0TE7ojoy7DWEXXJ7BY6uw/R29df6VLMzEZElmExF9ia87orbSvYJyJ6gf1AK3AREJLul/SIpD8o9AGSbpTUIamju7t7xL+Bs3Xx7Mn09PazefeRSpdiZjYisgwLFWjLP/lgsD51wGuAd6SPvyDpyjM6RtwREcsiYllbW9u51jtifJDbzMabLMOiC5if83oesG2wPulxiinAnrT9wYjYFRFHgDXA5RnWOqIunNlMjWCDLyhoZuNElmGxFlgsaaGkeuA6YHVen9XA9enza4DvR3Lq8/3ApZIa0xB5HfBUhrWOqIkTamlvbWLDjgOVLsXMbETUZfXGEdEr6SaSX/y1wJ0RsU7SrUBHRKwGPgd8SVInyR7Fdem6eyV9giRwAlgTEf+cVa1ZuHh2C+u3OyzMbHzILCwAImINyRBSbtstOc+PAdcOsu6XSabPjkkXz27h2+t2cKSnl8b6TDezmVnmfAZ3Ri6e1UIEdO70PbnNbOxzWGRk4BpRPjnPzMYDh0VGFrQ2MXFCjafPmtm44LDISG2NWDzTN0Iys/HBYZGhi2a1+FwLMxsXHBYZumR2C90Hj7PncE+lSzEzOycOiwydOsjt8y3MbGxzWGTokvOSsFi/3UNRZja2OSwyNLNlIm0tDazbtr/SpZiZnROHRcaWzpnMU9s8DGVmY5vDImNL50xm485DHDsxZu7dZGZ2BodFxpbOmUJff/CMp9Ca2RjmsMjY0jmTAVjnoSgzG8McFhmbP62RloY6H+Q2szHNYZGxmhrxkjmTvWdhZmNapmEhaYWkDZI6Jd1cYHmDpK+lyx+S1J63/HxJhyS9P8s6s/bSOVNYv/0Aff35tyA3MxsbMgsLSbXA7cBVwBJglaQled1uAPZGxIXAJ4Hb8pZ/EvhWVjWWy9I5kzl2op9N3b63hZmNTVnuWSwHOiNiU0T0AHcDK/P6rATuSp/fC1wpSQCS3gpsAtZlWGNZLJ3rg9xmNrZlGRZzga05r7vStoJ9IqIX2A+0SmoCPgB8eKgPkHSjpA5JHd3d3SNW+Ehb1NZMfV2ND3Kb2ZiVZVioQFv+oP1gfT4MfDIihhy3iYg7ImJZRCxra2s7yzKzN6G2hktmt3jPwszGrLoM37sLmJ/zeh6wbZA+XZLqgCnAHuCngWskfQyYCvRLOhYRn86w3kwtnTOZNU/uICJIR9rMzMaMLPcs1gKLJS2UVA9cB6zO67MauD59fg3w/UhcERHtEdEOfAr4s7EcFABL5kxh/9ETvLDvaKVLMTMbtszCIj0GcRNwP7AeuCci1km6VdLVabfPkRyj6ATeB5wxvXa8eKnP5DazMSzLYSgiYg2wJq/tlpznx4Bri7zHhzIprsxect5kamvEk137efPS2ZUux8xsWHwGd5lMnFDLJbNbeGzrvkqXYmY2bA6LMrps/lQe37qPfp/JbWZjjMOijC6bP5WDx3vZtMtncpvZ2OKwKKPL5k8F4NEtHooys7HFYVFGi9qaaWmo4/Euh4WZjS0OizKqqRGXzp/ig9xmNuY4LMrs5fOnsX77QQ4f7610KWZmJXNYlNnyhdPp6w8ftzCzMcVhUWaXL5hGjeDHz+2udClmZiVzWJRZc0MdL507hYee21PpUszMSuawqIDl7dN5dOs+jvf2VboUM7OSOCwqYPnC6fT09vNEl2+GZGZjg8OiAl7ZPh0Jfvisj1uY2djgsKiAaU31vGzuFB58ZvTeCtbMLJfDokJef1Ebj27Zy74jPZUuxcysqEzDQtIKSRskdUo648ZGkhokfS1d/pCk9rT9v0t6WNKT6eMbsqyzEl538Uz6A/5t465Kl2JmVlRmYSGpFrgduApYAqyStCSv2w3A3oi4EPgkcFvavgv4+Yh4GcltV7+UVZ2Vctn8qUxtnMC/bvBQlJmNflnuWSwHOiNiU0T0AHcDK/P6rATuSp/fC1wpSRHxaERsS9vXARMlNWRYa9nV1ogrFrfx4DPd9Pn+FmY2ymUZFnOBrTmvu9K2gn3Se3bvB1rz+rwdeDQijud/gKQbJXVI6ujuHnt/ob9pySx2HTrOQz6b28xGuSzDQgXa8v+EHrKPpKUkQ1O/XugDIuKOiFgWEcva2trOutBKeeNLZtHcUMd9j7xQ6VLMzIaUZVh0AfNzXs8Dtg3WR1IdMAXYk76eB9wHvCsins2wzoqZVF/LipfO5ls/2cGxEz6b28xGryzDYi2wWNJCSfXAdcDqvD6rSQ5gA1wDfD8iQtJU4J+BD0bEf2RYY8W97eVzOXS8lweeerHSpZiZDSqzsEiPQdwE3A+sB+6JiHWSbpV0ddrtc0CrpE7gfcDA9NqbgAuBP5b0WPo1M6taK+mnL2hl3rRJ3PGDTUQMfqA7IujceZCvd2zl7x99gYef30tvX38ZKzWzaqahfkGNJcuWLYuOjo5Kl3FWvt6xld+/9wk+887LWfHS805bFhF8d/1OPv6dDTy94+Bpy6ZMmsC7Xr2AX7viAqZMmlDOks1snJD0cEQsK9rPYVF5vX39vPlTP0ASf//en6W5oQ6Ahzbt5rZvP80jW/axcEYTv/qahbz6glYkWL/9AP/0+Ha+vW4HrU31fHjlUv7Hy85DKjRnwMysMIfFGPMvT+/k177YweKZzVzzinn828ZdPPhMN7MmN/C7b7yIa14xjwm1Z44a/uSF/fzv+57kia79vHnpLD6y8qXMnDyxAt+BmY1FDosx6AfPdPPerzzCweO9tDbV8+uvu4B3vbqdiRNqh1yvt6+fv/335/jEA88wsa6GP3rLEq59xTzvZZhZUQ6LMerQ8V56evuZ1jhh2L/sn+0+xAe/8SQ/3ryH11w4gz9/28uYP70xo0rNbDwoNSx81dlRprmhjulN9We1V7CorZm7b3wVH3nrS3l0y16u/MSDfPSfnuLFA8cyqNTMqon3LMapbfuO8okHnuGbj3QBcMXiNq5YPIOlc6Ywd+okJtXXcry3jwNHe9l/9AS7Dx/nxQPH2XnwGDsPHGfXoeMcPt7L0RP9HO/to65G1NfV0FBXy7TGCcxobqC1uZ7WpgZmtDQwo6meaU31TG+qZ2rjBBrqhh46M7PRwcNQBsDzuw9z99qtfOvJ7WzefaRo//raGmZObmBGcwPNDXVMnFBLw4Qa+vqCnr5+jp3oY++RE+w6dJw9h3sGvQhiU30tUyZNoL6uhvq6GibUJo91NUISNQIhamqgJt2LqhloTx8heayRUM7jwPIaCXHq9ak+A/0H3lPU1oi6mtzHGupqB2lPX9fW5C2vPX35qceanOVJe13tEP1qRE2NjyfZ6OCwsDPs2H+MjTsPsn3/MY6f6KO+roYpkyYweeIEWpsbmNnSwNRhHCvp7w/2H02CY9ehHvYeSb72HTnBnsM9HDh6gp6+fnp606++fnr7giDoj+Qckgjoj/Q1SVv/yfbT+wScXBbpOvmv89+7L4L+/qCvP+jtT977RF/lf+YlTguRutrCoVI7RFAVDqQ0LOFkaApOC1s41V5zWp+B52euR077mUF9qv1UUJ/6gyD3swfayQv8gn8I5LwWKvz+yqmB3Pc/9YfCabVxersG6ZdfV03NmXUUesz/w6bQ9zfalBoWdeUoxkaH2VMmMnvKyE2rrakR09Lhp8WzRuxty6I/DY8kRPpPhsnJx75T7X0R9PbF6X36+pP2k31PvdfpfftPf9/+gfdK2nvzXp9RxxnvF5xIA/hIT98ZnzMQxkmApqFJ+vxkkAIDfTg9cE/2LbAeeWHsK+sPX6EAKfRYMJByg6om531qxNI5U/i/q16eae0OC6tKNTWi/uRQkI+vnK3B9/wG9hjT0Ok/vU9/mlT9uev2x2nhVHCvMX0fyNkjzXkceJ+B/pHzPiffL+d9Tu3Nntkv9/1P3wPO+dz+M/eK+3O+/8H2gPO3V6Ga8/ewc9974HVf2vf86ZMy/7d2WJjZWTs5LFTwbgM2nnjqrJmZFeWwMDOzohwWZmZWlMPCzMyKyjQsJK2QtEFSp6SbCyxvkPS1dPlDktpzln0wbd8g6c1Z1mlmZkPLLCwk1QK3A1cBS4BVkpbkdbsB2BsRFwKfBG5L111CchvWpcAK4P+l72dmZhWQ5Z7FcqAzIjZFRA9wN7Ayr89K4K70+b3AlUpOcVwJ3B0RxyPiOaAzfT8zM6uALMNiLrA153VX2lawT3rP7v1Aa4nrmplZmWR5Ul6hs3TyLxAwWJ9S1kXSjcCN6ctDkjYMq8LTzQB2ncP6WXFdwzNa64LRW5vrGp7RWhecXW0LSumUZVh0AfNzXs8Dtg3Sp0tSHTAF2FPiukTEHcAdI1GspI5SLqZVbq5reEZrXTB6a3NdwzNa64Jsa8tyGGotsFjSQkn1JAesV+f1WQ1cnz6/Bvh+JJfBXQ1cl86WWggsBn6cYa1mZjaEzPYsIqJX0k3A/SRXarszItZJuhXoiIjVwOeAL0nqJNmjuC5dd52ke4CngF7gvRHRl1WtZmY2tEwvJBgRa4A1eW235Dw/Blw7yLp/CvxplvXlGZHhrAztY26FAAAFt0lEQVS4ruEZrXXB6K3NdQ3PaK0LMqxt3Nz8yMzMsuPLfZiZWVEOCzMzK6rqw6LY9avKWMd8Sf8iab2kdZJ+J23/kKQXJD2Wfv1cherbLOnJtIaOtG26pAckbUwfp5W5potztstjkg5I+t1KbDNJd0raKeknOW0Ft48Sf53+zD0h6fIy1/WXkp5OP/s+SVPT9nZJR3O222eyqmuI2gb9tyvX9eIGqetrOTVtlvRY2l62bTbE74jy/JxFeuu/avwimaX1LHABUA88DiypUC3nAZenz1uAZ0iuqfUh4P2jYFttBmbktX0MuDl9fjNwW4X/LXeQnGBU9m0GvBa4HPhJse0D/BzwLZKTT18FPFTmut4E1KXPb8upqz23X4W2WcF/u/T/wuNAA7Aw/X9bW6668pZ/HLil3NtsiN8RZfk5q/Y9i1KuX1UWEbE9Ih5Jnx8E1jP6L3GSe22vu4C3VrCWK4FnI+L5Snx4RPyAZPp3rsG2z0rgi5H4ETBV0nnlqisivhPJ5XUAfkRy0mvZDbLNBlO268UNVZckAb8I/F0Wnz2UIX5HlOXnrNrDYlReg0rJpdpfDjyUNt2U7kbeWe6hnhwBfEfSw0ouswIwKyK2Q/KDDMysUG2QnKOT+x94NGyzwbbPaPq5+1WSvz4HLJT0qKQHJV1RoZoK/duNlm12BfBiRGzMaSv7Nsv7HVGWn7NqD4uSrkFVTpKagW8AvxsRB4D/DywCLgO2k+wCV8LPRsTlJJecf6+k11aojjMouULA1cDX06bRss0GMyp+7iT9IclJr19Jm7YD50fEy4H3AV+VNLnMZQ32bzcqthmwitP/KCn7NivwO2LQrgXaznqbVXtYlHQNqnKRNIHkh+ArEfFNgIh4MSL6IqIf+BsqdKn2iNiWPu4E7kvreHFgtzZ93FmJ2kgC7JGIeDGtcVRsMwbfPhX/uZN0PfAW4B2RDnCnQzy70+cPkxwXuKicdQ3xbzcatlkd8DbgawNt5d5mhX5HUKafs2oPi1KuX1UW6Vjo54D1EfGJnPbcMcZfAH6Sv24ZamuS1DLwnOQA6U84/dpe1wP/UO7aUqf9tTcatllqsO2zGnhXOlvlVcD+gWGEcpC0AvgAcHVEHMlpb1N6kzFJF5Bck21TuepKP3ewf7vRcL24NwJPR0TXQEM5t9lgvyMo189ZOY7ij+YvkhkDz5D8RfCHFazjNSS7iE8Aj6VfPwd8CXgybV8NnFeB2i4gmYnyOLBuYDuR3Hvke8DG9HF6BWprBHYDU3Layr7NSMJqO3CC5C+6GwbbPiTDA7enP3NPAsvKXFcnyVj2wM/ZZ9K+b0//fR8HHgF+vgLbbNB/O+AP0222AbiqnHWl7V8AfiOvb9m22RC/I8ryc+bLfZiZWVHVPgxlZmYlcFiYmVlRDgszMyvKYWFmZkU5LMzMrCiHhdkwSOrT6Ve6HbErFadXMK3UOSFmQ8r0tqpm49DRiLis0kWYlZv3LMxGQHqPg9sk/Tj9ujBtXyDpe+mF8b4n6fy0fZaSe0k8nn79TPpWtZL+Jr1fwXckTarYN2WWw2FhNjyT8oahfiln2YGIWA58GvhU2vZpkstEX0pywb6/Ttv/GngwIn6K5N4J69L2xcDtEbEU2EdyhrBZxfkMbrNhkHQoIpoLtG8G3hARm9KLve2IiFZJu0guWXEibd8eETMkdQPzIuJ4znu0Aw9ExOL09QeACRHx0ey/M7Ohec/CbOTEIM8H61PI8Zznffi4oo0SDguzkfNLOY8/TJ//J8nVjAHeAfx7+vx7wG8CSKqtwH0jzIbFf7WYDc8kSY/lvP52RAxMn22Q9BDJH2Gr0rbfBu6U9PtAN/CetP13gDsk3UCyB/GbJFc6NRuVfMzCbASkxyyWRcSuStdilgUPQ5mZWVHeszAzs6K8Z2FmZkU5LMzMrCiHhZmZFeWwMDOzohwWZmZW1H8BPBcFRwR+qXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(EPOCH), loss_his)\n",
    "plt.title('training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.8652e+00,  3.4876e+00,  3.1461e+00,  ...,  3.2545e+00,\n",
       "           5.4733e-01, -4.3099e-01],\n",
       "         [ 4.2673e+00,  3.9057e+00,  3.5450e+00,  ...,  3.5891e+00,\n",
       "           7.0051e-01, -4.7614e-01],\n",
       "         [ 3.8388e+00,  3.4803e+00,  3.1106e+00,  ...,  3.2526e+00,\n",
       "           6.4846e-01, -4.2748e-01],\n",
       "         ...,\n",
       "         [ 4.2499e+00,  3.8838e+00,  3.5393e+00,  ...,  3.5715e+00,\n",
       "           6.5260e-01, -4.9448e-01],\n",
       "         [ 4.0520e+00,  3.7079e+00,  3.3298e+00,  ...,  3.4153e+00,\n",
       "           6.6125e-01, -4.5705e-01],\n",
       "         [ 3.7368e+00,  3.3691e+00,  3.0250e+00,  ...,  3.1574e+00,\n",
       "           5.5656e-01, -4.1503e-01]]], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_var = Variable(test).unsqueeze(0)\n",
    "out = net(test_var)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.detach().numpy()[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5663564123064484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(actual, pred)\n",
    "\n",
    "test = user_item_matrix(test_set)\n",
    "print('Autoencoder RMSEget_mse(out, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
